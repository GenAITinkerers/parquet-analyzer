{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb61fa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55a538da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Deekshitulu\\Learning\\GenAi\\parquet-analyzer\\notebooks\n"
     ]
    }
   ],
   "source": [
    "# pwd\n",
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "724dbcff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         time        TO  sensor1_min  sensor1_max  sensor2_min  sensor2_max  \\\n",
      "0  1743532199  10540337        65.83        65.27         10.0         98.0   \n",
      "1  1743618599  10540337        76.09        54.77         10.0         98.0   \n",
      "2  1743704999  10540337        67.66        66.12         10.0         99.0   \n",
      "3  1743791399  10540337        83.22        80.61         10.0         99.0   \n",
      "4  1743877799  10540337        78.29        66.14         10.0         99.0   \n",
      "\n",
      "   sensor2_mean  sensor3_min  sensor3_max  sensor3_mean  \n",
      "0         55.59         12.0         99.0         54.11  \n",
      "1         57.70         10.0         99.0         51.68  \n",
      "2         50.29         10.0         98.0         53.25  \n",
      "3         58.97         11.0         98.0         49.92  \n",
      "4         59.60         10.0         99.0         61.02  \n",
      "CSV file converted to Parquet and saved at: ../data/processed/training_data.parquet\n",
      "         time        TO  sensor1_min  sensor1_max  sensor2_min  sensor2_max  \\\n",
      "0  1743532199  10540337        65.83        65.27         10.0         98.0   \n",
      "1  1743618599  10540337        76.09        54.77         10.0         98.0   \n",
      "2  1743704999  10540337        67.66        66.12         10.0         99.0   \n",
      "3  1743791399  10540337        83.22        80.61         10.0         99.0   \n",
      "4  1743877799  10540337        78.29        66.14         10.0         99.0   \n",
      "\n",
      "   sensor2_mean  sensor3_min  sensor3_max  sensor3_mean  \n",
      "0         55.59         12.0         99.0         54.11  \n",
      "1         57.70         10.0         99.0         51.68  \n",
      "2         50.29         10.0         98.0         53.25  \n",
      "3         58.97         11.0         98.0         49.92  \n",
      "4         59.60         10.0         99.0         61.02  \n"
     ]
    }
   ],
   "source": [
    "# Step 1: Read CSV files\n",
    "csv_file_path = \"../data/raw/training_data.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "print(df.head())  # Display the first few rows of the DataFrame\n",
    "\n",
    "# Step 2: Write to Parquet file\n",
    "processed_directory = \"../data/processed\"\n",
    "os.makedirs(processed_directory, exist_ok=True)  # Create directory if it doesn't exist\n",
    "parquet_file_path = \"../data/processed/training_data.parquet\"\n",
    "df.to_parquet(parquet_file_path, engine='pyarrow')  # or engine='fastparquet'\n",
    "\n",
    "print(f\"CSV file converted to Parquet and saved at: {parquet_file_path}\")\n",
    "df = pd.read_parquet(parquet_file_path)\n",
    "print(df.head())  # Display the first few rows of the DataFrame from Parquet file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cdf7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write method to convert CSV to Parquet# Function to convert CSV to Parquet\n",
    "def csv_to_parquet(csv_path, parquet_path):\n",
    "    \"\"\"\n",
    "    Convert a CSV file to Parquet format.\n",
    "    \n",
    "    Parameters:\n",
    "    csv_path (str): Path to the input CSV file.\n",
    "    parquet_path (str): Path where the output Parquet file will be saved.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.to_parquet(parquet_path, engine='pyarrow')\n",
    "    print(f\"CSV file converted to Parquet and saved at: {parquet_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e433484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_parquet(csv_path, parquet_path, engine='pyarrow'):\n",
    "    \"\"\"\n",
    "    Converts a CSV file to a Parquet file.\n",
    "\n",
    "    Args:\n",
    "        csv_path (str): Path to the input CSV file.\n",
    "        parquet_path (str): Path to the output Parquet file.\n",
    "        engine (str): Parquet engine ('pyarrow' or 'fastparquet').\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.to_parquet(parquet_path, engine=engine)\n",
    "    print(f\"Converted {csv_path} to {parquet_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe7aa237",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"../data/raw/training_data.csv\"\n",
    "parquet_path = \"../data/processed/training_data.parquet\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d96c681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted ../data/raw/training_data.csv to ../data/processed/training_data.parquet\n"
     ]
    }
   ],
   "source": [
    "csv_to_parquet(csv_path, parquet_path, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67449920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         time        TO  sensor1_min  sensor1_max  sensor2_min  sensor2_max  \\\n",
      "0  1743532199  10540337        65.83        65.27         10.0         98.0   \n",
      "1  1743618599  10540337        76.09        54.77         10.0         98.0   \n",
      "2  1743704999  10540337        67.66        66.12         10.0         99.0   \n",
      "3  1743791399  10540337        83.22        80.61         10.0         99.0   \n",
      "4  1743877799  10540337        78.29        66.14         10.0         99.0   \n",
      "\n",
      "   sensor2_mean  sensor3_min  sensor3_max  sensor3_mean  \n",
      "0         55.59         12.0         99.0         54.11  \n",
      "1         57.70         10.0         99.0         51.68  \n",
      "2         50.29         10.0         98.0         53.25  \n",
      "3         58.97         11.0         98.0         49.92  \n",
      "4         59.60         10.0         99.0         61.02  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(parquet_path)\n",
    "print(df.head())  # Display the first few rows of the DataFrame loaded from Parquet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-env_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
